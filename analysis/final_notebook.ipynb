{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95604010",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This analysis seeks to bring understanding to data regarding police interactions known as Terry stops. According to [Merriam-Webster](https://www.merriam-webster.com/legal/Terry%20stop), a Terry stop is \"a stop and limited search of a person for weapons justified by a police officer's reasonable conclusion that a crime is being or about to be committed by a person who may be armed and whose responses to questioning do not dispel the officer's fear of danger to the officer or to others.\" \n",
    "\n",
    "## Data Sources\n",
    "\n",
    "The city of Seattle [provides](https://data.seattle.gov/Public-Safety/Terry-Stops/28ny-9ts8) substantial publicly available data about these encounters. There are over 47,000 records spanning a period from 2015 to 2021. It includes 23 different features, including topics such as race, gender, age, location, call type, and the final resolution of the stop -- whether it ended in arrest or citation, for example.\n",
    "\n",
    "## The Process\n",
    "This analysis will follow the general structure listed here:\n",
    "1. Setup and Data Import\n",
    "2. Data Cleaning\n",
    "3. Feature Engineering\n",
    "4. Graphical Exploratory Data Analysis (EDA)\n",
    "5. Feature Selection\n",
    "6. Modeling\n",
    "7. Results Interpretation\n",
    "8. Conclusion\n",
    "\n",
    "### Additional Notes\n",
    "This notebook provides a somewhat condensed analysis compared to the full sequence necessary to understand the all details of choosing specific models and the nitty-gritty details of feature selection. Please refer to the EDA notebook in this folder for that analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de63bb",
   "metadata": {},
   "source": [
    "## Part I: Setup and Data Import\n",
    "**Import relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfebee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os, sys\n",
    "from datetime import time\n",
    "\n",
    "# Data manipulation packages\n",
    "from custom_functions import *\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model evaluation packages\n",
    "import shap\n",
    "from sklearn.metrics import f1_score, plot_confusion_matrix\n",
    "\n",
    "# Basic settings for an easier to use notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54211d7",
   "metadata": {},
   "source": [
    "**Declare static variables used throughout notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12f1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global static variable declarations used throughout notebook\n",
    "RANDOM_STATE = 0\n",
    "raw_terry_path = os.path.join('..', 'data', 'raw', 'terry-stops.csv')\n",
    "processed_data_path = os.path.join('..', 'data', 'processed')\n",
    "UNKNOWN = 'Not provided'\n",
    "N_SPLITS = 3\n",
    "JOBS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a3eee",
   "metadata": {},
   "source": [
    "**Import full dataset from *data* folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e07251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(raw_terry_path, dtype='str')\n",
    "\n",
    "# Strip spaces, as relevant\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedf1ec",
   "metadata": {},
   "source": [
    "# Part II: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb7c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
